{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Exercise4-Question.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/lmoroney/dlaicourse/blob/master/Exercises/Exercise%204%20-%20Handling%20Complex%20Images/Exercise%204-Question.ipynb","timestamp":1564859398895}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UncprnB0ymAE","colab_type":"text"},"source":["Below is code with a link to a happy or sad dataset which contains 80 images, 40 happy and 40 sad. \n","Create a convolutional neural network that trains to 100% accuracy on these images,  which cancels training upon hitting training accuracy of >.999\n","\n","Hint -- it will work best with 3 convolutional layers."]},{"cell_type":"code","metadata":{"id":"7Vti6p3PxmpS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"199f39d6-a1fb-4084-fb0c-607c1010eb11","executionInfo":{"status":"ok","timestamp":1564859346766,"user_tz":-60,"elapsed":7995,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["import tensorflow as tf\n","import os\n","import zipfile\n","\n","\n","DESIRED_ACCURACY = 0.999\n","\n","!wget --no-check-certificate \\\n","    \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\" \\\n","    -O \"/tmp/happy-or-sad.zip\"\n","\n","zip_ref = zipfile.ZipFile(\"/tmp/happy-or-sad.zip\", 'r')\n","zip_ref.extractall(\"/tmp/h-or-s\")\n","zip_ref.close()\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs=None):\n","    if(logs.get('acc') > 0.999):\n","        print(\"Epoch %05d: early stopping Threshold\" % epoch)\n","        self.model.stop_training = True\n","\n","    \n","callbacks = myCallback()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2019-08-03 19:09:00--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c09::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2670333 (2.5M) [application/zip]\n","Saving to: ‘/tmp/happy-or-sad.zip’\n","\n","/tmp/happy-or-sad.z 100%[===================>]   2.55M  --.-KB/s    in 0.02s   \n","\n","2019-08-03 19:09:05 (159 MB/s) - ‘/tmp/happy-or-sad.zip’ saved [2670333/2670333]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6DLGbXXI1j_V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":598},"outputId":"01485eff-071a-42be-ead4-994029aac442","executionInfo":{"status":"ok","timestamp":1564859346995,"user_tz":-60,"elapsed":8208,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["# This Code Block should Define and Compile the Model\n","model = tf.keras.models.Sequential([\n","# Your Code Here\n","    tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.summary()\n","\n","from tensorflow.keras.optimizers import RMSprop\n","\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=RMSprop(lr = 0.001),\n","              metrics=['acc'])"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0803 19:09:06.351371 139722563446656 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0803 19:09:06.602455 139722563446656 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 148, 148, 16)      448       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 72, 72, 16)        2320      \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 36, 36, 16)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 34, 34, 16)        2320      \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 17, 17, 16)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 4624)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               2368000   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 513       \n","=================================================================\n","Total params: 2,373,601\n","Trainable params: 2,373,601\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Ap9fUJE1vVu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"18c97234-2673-4262-a884-cdf30352ae57","executionInfo":{"status":"ok","timestamp":1564859347280,"user_tz":-60,"elapsed":8477,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["# This code block should create an instance of an ImageDataGenerator called train_datagen \n","# And a train_generator by calling train_datagen.flow_from_directory\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale=1/255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        '/tmp/h-or-s',\n","        target_size=(150, 150),\n","        batch_size=10,\n","        class_mode='binary')\n","        # Your Code Here)\n","\n","# Expected output: 'Found 80 images belonging to 2 classes'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Found 80 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"48dLm13U1-Le","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"6ab90e7a-6c6c-48df-fca5-ddf7cebcf3ad","executionInfo":{"status":"ok","timestamp":1564859351339,"user_tz":-60,"elapsed":12521,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["# This code block should call model.fit_generator and train for\n","# a number of epochs. \n","history = model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=2,\n","    epochs=15,\n","    verbose=1,\n","    callbacks=[callbacks])\n","      # Your Code Here)\n","    \n","# Expected output: \"Reached 99.9% accuracy so cancelling training!\"\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","2/2 [==============================] - 1s 711ms/step - loss: 2.0404 - acc: 0.5000\n","Epoch 2/15\n","2/2 [==============================] - 0s 174ms/step - loss: 0.7103 - acc: 0.5500\n","Epoch 3/15\n","2/2 [==============================] - 0s 173ms/step - loss: 0.6517 - acc: 0.7000\n","Epoch 4/15\n","2/2 [==============================] - 0s 204ms/step - loss: 0.6251 - acc: 0.4500\n","Epoch 5/15\n","2/2 [==============================] - 0s 209ms/step - loss: 0.5054 - acc: 0.6000\n","Epoch 6/15\n","2/2 [==============================] - 0s 172ms/step - loss: 0.3842 - acc: 0.9500\n","Epoch 7/15\n","1/2 [==============>...............] - ETA: 0s - loss: 0.2719 - acc: 1.0000Epoch 00006: early stopping Threshold\n","2/2 [==============================] - 0s 171ms/step - loss: 0.2158 - acc: 1.0000\n"],"name":"stdout"}]}]}